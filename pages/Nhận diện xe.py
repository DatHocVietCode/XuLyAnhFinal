import math
import os as os
import tempfile

import cv2
import numpy as np
import streamlit as st
from PIL import Image
from streamlit_drawable_canvas import st_canvas
from ultralytics import YOLO

st.markdown(
    """
    <style>
    .stApp {
        background-image: url("https://moewalls.com/wp-content/uploads/2024/11/cat-floating-on-the-water-thumb-728x410.jpg");
        background-size: cover;
        background-position: center;
        color: white;
    }
    
    .title {
        color: ;
        font-size: 3em;
        text-align: center;
        font-weight: bold;
        margin-bottom: 0.5em;
        text-shadow: 2px 2px 5px black;
    }
    .subtitle {
        color: white;
        font-size: 1.5em;
        text-align: center;
        margin-bottom: 2em;
        text-shadow: 1px 1px 3px black;
    }
    .section-title {
        color: white;
        font-size: 1.2em;
        margin-bottom: 0.5em;
        text-shadow: 1px 1px 2px black;
    }
    .info {
        color: white;
        font-size: 1em;
        margin-bottom: 1em;
        text-shadow: 1px 1px 2px black;
    }
    </style>
    """,
    unsafe_allow_html=True
)
st.markdown(
    """
    <style>
    /* L√†m cho sidebar trong su·ªët v√† ch·ªØ m√†u ƒëen */
    [data-testid="stSidebar"] {
        background-color: transparent !important;  /* N·ªÅn trong su·ªët */
        color: #000000 !important;  /* M√†u ch·ªØ ƒëen */
    }

    /* ƒê·ªïi m√†u ti√™u ƒë·ªÅ trong sidebar */
    [data-testid="stSidebar"] h1, [data-testid="stSidebar"] h2 {
        color: #000000 !important;  /* M√†u ch·ªØ ƒëen cho ti√™u ƒë·ªÅ */
    }

    /* ƒê·ªïi m√†u c√°c item trong sidebar */
    [data-testid="stSidebarNav"] ul li a {
        color: #000000 !important;  /* M√†u ch·ªØ ƒëen cho c√°c item */
        font-size: 1.1em;  /* TƒÉng k√≠ch th∆∞·ªõc ch·ªØ cho d·ªÖ ƒë·ªçc */
        padding: 10px;
    }

    /* M√†u khi hover (di chu·ªôt v√†o) */
    [data-testid="stSidebarNav"] ul li a:hover {
        background-color: #D1D5DB;  /* M√†u n·ªÅn khi hover */
        color: black;  /* M√†u ch·ªØ ƒëen khi hover */
    }

    /* Th√™m hi·ªáu ·ª©ng cho c√°c item trong sidebar */
    [data-testid="stSidebarNav"] ul li {
        border-radius: 5px;  /* Bo g√≥c cho c√°c item */
        transition: background-color 0.3s ease;  /* Hi·ªáu ·ª©ng chuy·ªÉn m√†u m∆∞·ª£t m√† */
    }
    </style>
    """,
    unsafe_allow_html=True
)
st.title("Nh·∫≠n d·∫°ng lo·∫°i xe v√† ƒë·∫øm s·ªë xe theo th·ªùi gian")
if "show_video" not in st.session_state:
    st.session_state.show_video = False
# Kh·ªüi t·∫°o session state ƒë·ªÉ l∆∞u t·ªça ƒë·ªô line v√† background image
if 'start_line' not in st.session_state:
    st.session_state.start_line = None
if 'end_line' not in st.session_state:
    st.session_state.end_line = None
if 'canvas_key' not in st.session_state:
    st.session_state.canvas_key = 0
if 'background_image' not in st.session_state:
    st.session_state.background_image = None

# --- Drag and drop video ---
st.subheader("üì§ Ch·ªçn video ƒë·ªÉ x·ª≠ l√Ω")
uploaded_file = st.file_uploader("K√©o th·∫£ ho·∫∑c ch·ªçn m·ªôt file video (.mp4)", type=["mp4", "avi"], key="custom_video_uploader")
# --- Drag and drop image ---
st.subheader("üì§ Ch·ªçn ·∫£nh ƒë·ªÉ x·ª≠ l√Ω")
uploaded_image = st.file_uploader("K√©o th·∫£ ho·∫∑c ch·ªçn m·ªôt file ·∫£nh (.jpg, .png)", type=["jpg", "png"], key="custom_image_uploader")

base_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
print(base_path)
model = YOLO(os.path.join(base_path, 'vehicles_counting-master/model2/dataset/runs/detect/train/weights/best.pt'))
# L·∫•y danh s√°ch c√°c l·ªõp t·ª´ model ƒë√£ train
CLASSES = model.names
print(CLASSES)
#VEHICLE_CLASSES = [k for k, v in CLASSES.items() if v in ["car", "motorbike", "bus", "truck"]]
VEHICLE_CLASSES = [k for k, v in CLASSES.items() if v == "Vehicle"]
# Thi·∫øt l·∫≠p m·ªôt s·ªë tham s·ªë
CONFIDENCE_SETTING = 0.7
MAX_DISTANCE = 120



def detections_yolo(image):
    results = model.predict(image)

    boxes = []
    class_ids = []
    confidences = []

    for r in results:
        for box in r.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            confidence = float(box.conf[0])
            class_id = int(box.cls[0])

            if confidence > CONFIDENCE_SETTING and class_id in VEHICLE_CLASSES:
                print(f"Object: {CLASSES[class_id]} - Confidence: {confidence:.2f}")
                boxes.append([x1, y1, x2 - x1, y2 - y1])
                class_ids.append(class_id)
                confidences.append(confidence)

    return boxes, class_ids, confidences



def draw_prediction(classes, colors, img, class_id, confidence, x, y, width, height):
    """
    Draw bounding box and put classe text and confidence
    :param classes: name of object
    :param colors: color for object
    :param img: immage
    :param class_id: class_id of this object
    :param confidence: confidence
    :param x: top, left
    :param y: top, left
    :param width: width of bounding box
    :param height: height of bounding box
    :return: None
    """
    try:
        label = str(classes[class_id])
        color = colors[class_id]
        center_x = int(x + width / 2.0)
        center_y = int(y + height / 2.0)
        x = int(x)
        y = int(y)
        width = int(width)
        height = int(height)

        cv2.rectangle(img, (x, y), (x + width, y + height), color, 1)
        cv2.circle(img, (center_x, center_y), 2, (0, 255, 0), -1)
        cv2.putText(img, label + ": {:0.2f}%".format(confidence * 100), (x, y - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
    except (Exception, cv2.error) as e:
        print("Can't draw prediction for class_id {}: {}".format(class_id, e))

def detect_vehicle(video_input, video_output, skip_frame=1):
    """
    Ph√°t hi·ªán ph∆∞∆°ng ti·ªán trong video v√† l∆∞u k·∫øt qu·∫£ v√†o video ƒë·∫ßu ra.

    Args:
        video_input (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn video ƒë·∫ßu v√†o.
        video_output (str): ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u video sau khi x·ª≠ l√Ω.
        skip_frame (int): S·ªë l∆∞·ª£ng frame b·ªè qua gi·ªØa m·ªói l·∫ßn nh·∫≠n di·ªán (gi√∫p t·ªëi ∆∞u t·ªëc ƒë·ªô).

    Returns:
        None
    """
    # T·∫°o m√†u s·∫Øc ng·∫´u nhi√™n cho t·ª´ng class
    colors = np.random.uniform(0, 255, size=(len(CLASSES), 3))

    # Load video
    cap = cv2.VideoCapture(video_input)
    ret_val, frame = cap.read()
    width = frame.shape[1]
    height = frame.shape[0]

    # ƒê·ªãnh d·∫°ng video ƒë·∫ßu ra
    video_format = cv2.VideoWriter_fourcc(*'XVID')
    out = cv2.VideoWriter(video_output, video_format, 25, (width, height))

    # Danh s√°ch c√°c ƒë·ªëi t∆∞·ª£ng ƒëang theo d√µi
    list_object = []

    # T·∫°o v√πng hi·ªÉn th·ªã tr√™n Streamlit
    frame_container = st.empty()

    number_frame = 0  # Bi·∫øn ƒë·∫øm s·ªë frame

    while cap.isOpened():
        number_frame += 1
        ret_val, frame = cap.read()
        if frame is None:
            break

        # ‚ú® **Detect object m·ªõi m·ªói skip_frame**
        if number_frame % skip_frame == 0:
            results = model.predict(frame)
            for r in results:
                for box in r.boxes:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    confidence = float(box.conf[0])
                    class_id = int(box.cls[0])

                    if confidence > CONFIDENCE_SETTING and class_id in VEHICLE_CLASSES:
                        box_width, box_height = x2 - x1, y2 - y1

                        # ‚ú® **V·∫Ω bounding box c·ªßa ph∆∞∆°ng ti·ªán**
                        draw_prediction(CLASSES, colors, frame, class_id, confidence,
                                        x1, y1, box_width, box_height)

        # Hi·ªÉn th·ªã frame tr√™n Streamlit
        frame_container.image(frame, channels='BGR')
        out.write(frame)

    cap.release()
    out.release()
    cv2.destroyAllWindows()

def detect_vehicle_from_image(image_input, image_output):
    """
    Ph√°t hi·ªán ph∆∞∆°ng ti·ªán trong ·∫£nh v√† l∆∞u k·∫øt qu·∫£ v√†o ·∫£nh ƒë·∫ßu ra.

    Args:
        image_input (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh ƒë·∫ßu v√†o.
        image_output (str): ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u ·∫£nh sau khi x·ª≠ l√Ω.

    Returns:
        None
    """
    # T·∫°o m√†u s·∫Øc ng·∫´u nhi√™n cho t·ª´ng class
    colors = np.random.uniform(0, 255, size=(len(CLASSES), 3))

    # ƒê·ªçc ·∫£nh
    img = cv2.imread(image_input)

    # D·ª± ƒëo√°n ph∆∞∆°ng ti·ªán
    results = model.predict(img)

    for r in results:
        for box in r.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            confidence = float(box.conf[0])
            class_id = int(box.cls[0])

            if confidence > CONFIDENCE_SETTING and class_id in VEHICLE_CLASSES:
                box_width, box_height = x2 - x1, y2 - y1

                # V·∫Ω bounding box c·ªßa ph∆∞∆°ng ti·ªán
                draw_prediction(CLASSES, colors, img, class_id, confidence,
                                x1, y1, box_width, box_height)

    # L∆∞u ·∫£nh k·∫øt qu·∫£
    cv2.imwrite(image_output, img)



# --- M·∫∑c ƒë·ªãnh ch·∫°y video highway.mp4 n·∫øu ch∆∞a c√≥ upload ---
default_video = os.path.join(base_path, "vehicles_counting-master", "Vehicle_Detection_on_Highway_Traffic_Lanes.mp4")
st.subheader("üéûÔ∏è Video m·∫∑c ƒë·ªãnh")
if st.button("‚ñ∂ X·ª≠ l√Ω video m·∫∑c ƒë·ªãnh"):
    output_default = os.path.join(tempfile.gettempdir(), "default_output.avi")
    detect_vehicle(default_video, output_default)
    st.video(output_default)
    st.session_state.show_video = True
    
if uploaded_file is not None:
    # ƒê·ªçc video
    if uploaded_file is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_file.read())
        tfile.close()  # Close the file after writing
        video_path = tfile.name
    else:
        video_path = default_video

    
    # L·∫•y frame ƒë·∫ßu ti√™n
    cap = cv2.VideoCapture(video_path)
    ret, frame = cap.read()
    cap.release()

    if ret:
        if st.button("üöó B·∫Øt ƒë·∫ßu nh·∫≠n d·∫°ng xe"):
            output_path = os.path.join(tempfile.gettempdir(), "output.avi")
            detect_vehicle(video_path, output_path)


# --- Upload ·∫£nh v√† x·ª≠ l√Ω ---
if uploaded_image is not None:
    # L∆∞u ·∫£nh t·∫°m th·ªùi
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(uploaded_image.read())
    tfile.close()  # Close the file after writing
    image_path = tfile.name

    # Hi·ªÉn th·ªã ·∫£nh g·ªëc l√™n Streamlit
    st.image(image_path, caption="·∫¢nh g·ªëc", use_column_width=True)

    if st.button("üöó Nh·∫≠n d·∫°ng ph∆∞∆°ng ti·ªán trong ·∫£nh"):
        output_image = os.path.join(tempfile.gettempdir(), "output_image.jpg")
        detect_vehicle_from_image(image_path, output_image)

        # Hi·ªÉn th·ªã ·∫£nh ƒë√£ x·ª≠ l√Ω
        st.image(output_image, caption="·∫¢nh ƒë√£ x·ª≠ l√Ω", use_column_width=True)

