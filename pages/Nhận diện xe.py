import math
import os as os
import tempfile

import cv2
import numpy as np
import streamlit as st
from PIL import Image
from streamlit_drawable_canvas import st_canvas
from ultralytics import YOLO

st.title("Nháº­n dáº¡ng loáº¡i xe vÃ  Ä‘áº¿m sá»‘ xe theo thá»i gian")
if "show_video" not in st.session_state:
    st.session_state.show_video = False
# Khá»Ÿi táº¡o session state Ä‘á»ƒ lÆ°u tá»a Ä‘á»™ line vÃ  background image
if 'start_line' not in st.session_state:
    st.session_state.start_line = None
if 'end_line' not in st.session_state:
    st.session_state.end_line = None
if 'canvas_key' not in st.session_state:
    st.session_state.canvas_key = 0
if 'background_image' not in st.session_state:
    st.session_state.background_image = None

# --- Drag and drop video ---
st.subheader("ğŸ“¤ Chá»n video Ä‘á»ƒ xá»­ lÃ½")
uploaded_file = st.file_uploader("KÃ©o tháº£ hoáº·c chá»n má»™t file video (.mp4)", type=["mp4", "avi"], key="custom_video_uploader")
# --- Drag and drop image ---
st.subheader("ğŸ“¤ Chá»n áº£nh Ä‘á»ƒ xá»­ lÃ½")
uploaded_image = st.file_uploader("KÃ©o tháº£ hoáº·c chá»n má»™t file áº£nh (.jpg, .png)", type=["jpg", "png"], key="custom_image_uploader")

base_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
print(base_path)
model = YOLO(os.path.join(base_path, 'vehicles_counting-master/model2/dataset/runs/detect/train/weights/best.pt'))
# Láº¥y danh sÃ¡ch cÃ¡c lá»›p tá»« model Ä‘Ã£ train
CLASSES = model.names
print(CLASSES)
#VEHICLE_CLASSES = [k for k, v in CLASSES.items() if v in ["car", "motorbike", "bus", "truck"]]
VEHICLE_CLASSES = [k for k, v in CLASSES.items() if v == "Vehicle"]
# Thiáº¿t láº­p má»™t sá»‘ tham sá»‘
CONFIDENCE_SETTING = 0.7
MAX_DISTANCE = 120



def detections_yolo(image):
    results = model.predict(image)

    boxes = []
    class_ids = []
    confidences = []

    for r in results:
        for box in r.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            confidence = float(box.conf[0])
            class_id = int(box.cls[0])

            if confidence > CONFIDENCE_SETTING and class_id in VEHICLE_CLASSES:
                print(f"Object: {CLASSES[class_id]} - Confidence: {confidence:.2f}")
                boxes.append([x1, y1, x2 - x1, y2 - y1])
                class_ids.append(class_id)
                confidences.append(confidence)

    return boxes, class_ids, confidences



def draw_prediction(classes, colors, img, class_id, confidence, x, y, width, height):
    """
    Draw bounding box and put classe text and confidence
    :param classes: name of object
    :param colors: color for object
    :param img: immage
    :param class_id: class_id of this object
    :param confidence: confidence
    :param x: top, left
    :param y: top, left
    :param width: width of bounding box
    :param height: height of bounding box
    :return: None
    """
    try:
        label = str(classes[class_id])
        color = colors[class_id]
        center_x = int(x + width / 2.0)
        center_y = int(y + height / 2.0)
        x = int(x)
        y = int(y)
        width = int(width)
        height = int(height)

        cv2.rectangle(img, (x, y), (x + width, y + height), color, 1)
        cv2.circle(img, (center_x, center_y), 2, (0, 255, 0), -1)
        cv2.putText(img, label + ": {:0.2f}%".format(confidence * 100), (x, y - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
    except (Exception, cv2.error) as e:
        print("Can't draw prediction for class_id {}: {}".format(class_id, e))

def detect_vehicle(video_input, video_output, skip_frame=1):
    """
    PhÃ¡t hiá»‡n phÆ°Æ¡ng tiá»‡n trong video vÃ  lÆ°u káº¿t quáº£ vÃ o video Ä‘áº§u ra.

    Args:
        video_input (str): ÄÆ°á»ng dáº«n Ä‘áº¿n video Ä‘áº§u vÃ o.
        video_output (str): ÄÆ°á»ng dáº«n Ä‘á»ƒ lÆ°u video sau khi xá»­ lÃ½.
        skip_frame (int): Sá»‘ lÆ°á»£ng frame bá» qua giá»¯a má»—i láº§n nháº­n diá»‡n (giÃºp tá»‘i Æ°u tá»‘c Ä‘á»™).

    Returns:
        None
    """
    # Táº¡o mÃ u sáº¯c ngáº«u nhiÃªn cho tá»«ng class
    colors = np.random.uniform(0, 255, size=(len(CLASSES), 3))

    # Load video
    cap = cv2.VideoCapture(video_input)
    ret_val, frame = cap.read()
    width = frame.shape[1]
    height = frame.shape[0]

    # Äá»‹nh dáº¡ng video Ä‘áº§u ra
    video_format = cv2.VideoWriter_fourcc(*'XVID')
    out = cv2.VideoWriter(video_output, video_format, 25, (width, height))

    # Danh sÃ¡ch cÃ¡c Ä‘á»‘i tÆ°á»£ng Ä‘ang theo dÃµi
    list_object = []

    # Táº¡o vÃ¹ng hiá»ƒn thá»‹ trÃªn Streamlit
    frame_container = st.empty()

    number_frame = 0  # Biáº¿n Ä‘áº¿m sá»‘ frame

    while cap.isOpened():
        number_frame += 1
        ret_val, frame = cap.read()
        if frame is None:
            break

        # âœ¨ **Detect object má»›i má»—i skip_frame**
        if number_frame % skip_frame == 0:
            results = model.predict(frame)
            for r in results:
                for box in r.boxes:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    confidence = float(box.conf[0])
                    class_id = int(box.cls[0])

                    if confidence > CONFIDENCE_SETTING and class_id in VEHICLE_CLASSES:
                        box_width, box_height = x2 - x1, y2 - y1

                        # âœ¨ **Váº½ bounding box cá»§a phÆ°Æ¡ng tiá»‡n**
                        draw_prediction(CLASSES, colors, frame, class_id, confidence,
                                        x1, y1, box_width, box_height)

        # Hiá»ƒn thá»‹ frame trÃªn Streamlit
        frame_container.image(frame, channels='BGR')
        out.write(frame)

    cap.release()
    out.release()
    cv2.destroyAllWindows()

def detect_vehicle_from_image(image_input, image_output):
    """
    PhÃ¡t hiá»‡n phÆ°Æ¡ng tiá»‡n trong áº£nh vÃ  lÆ°u káº¿t quáº£ vÃ o áº£nh Ä‘áº§u ra.

    Args:
        image_input (str): ÄÆ°á»ng dáº«n Ä‘áº¿n áº£nh Ä‘áº§u vÃ o.
        image_output (str): ÄÆ°á»ng dáº«n Ä‘á»ƒ lÆ°u áº£nh sau khi xá»­ lÃ½.

    Returns:
        None
    """
    # Táº¡o mÃ u sáº¯c ngáº«u nhiÃªn cho tá»«ng class
    colors = np.random.uniform(0, 255, size=(len(CLASSES), 3))

    # Äá»c áº£nh
    img = cv2.imread(image_input)

    # Dá»± Ä‘oÃ¡n phÆ°Æ¡ng tiá»‡n
    results = model.predict(img)

    for r in results:
        for box in r.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            confidence = float(box.conf[0])
            class_id = int(box.cls[0])

            if confidence > CONFIDENCE_SETTING and class_id in VEHICLE_CLASSES:
                box_width, box_height = x2 - x1, y2 - y1

                # Váº½ bounding box cá»§a phÆ°Æ¡ng tiá»‡n
                draw_prediction(CLASSES, colors, img, class_id, confidence,
                                x1, y1, box_width, box_height)

    # LÆ°u áº£nh káº¿t quáº£
    cv2.imwrite(image_output, img)



# --- Máº·c Ä‘á»‹nh cháº¡y video highway.mp4 náº¿u chÆ°a cÃ³ upload ---
default_video = os.path.join(base_path, "vehicles_counting-master", "Vehicle_Detection_on_Highway_Traffic_Lanes.mp4")
st.subheader("ğŸï¸ Video máº·c Ä‘á»‹nh")
if st.button("â–¶ Xá»­ lÃ½ video máº·c Ä‘á»‹nh"):
    output_default = os.path.join(tempfile.gettempdir(), "default_output.avi")
    detect_vehicle(default_video, output_default)
    st.video(output_default)
    st.session_state.show_video = True
    
if uploaded_file is not None:
    # Äá»c video
    if uploaded_file is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_file.read())
        tfile.close()  # Close the file after writing
        video_path = tfile.name
    else:
        video_path = default_video

    
    # Láº¥y frame Ä‘áº§u tiÃªn
    cap = cv2.VideoCapture(video_path)
    ret, frame = cap.read()
    cap.release()

    if ret:
        if st.button("ğŸš— Báº¯t Ä‘áº§u nháº­n dáº¡ng xe"):
            output_path = os.path.join(tempfile.gettempdir(), "output.avi")
            detect_vehicle(video_path, output_path)


# --- Upload áº£nh vÃ  xá»­ lÃ½ ---
if uploaded_image is not None:
    # LÆ°u áº£nh táº¡m thá»i
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(uploaded_image.read())
    tfile.close()  # Close the file after writing
    image_path = tfile.name

    # Hiá»ƒn thá»‹ áº£nh gá»‘c lÃªn Streamlit
    st.image(image_path, caption="áº¢nh gá»‘c", use_column_width=True)

    if st.button("ğŸš— Nháº­n dáº¡ng phÆ°Æ¡ng tiá»‡n trong áº£nh"):
        output_image = os.path.join(tempfile.gettempdir(), "output_image.jpg")
        detect_vehicle_from_image(image_path, output_image)

        # Hiá»ƒn thá»‹ áº£nh Ä‘Ã£ xá»­ lÃ½
        st.image(output_image, caption="áº¢nh Ä‘Ã£ xá»­ lÃ½", use_column_width=True)

